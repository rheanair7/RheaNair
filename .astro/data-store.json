[["Map",1,2,9,10,198,199],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.13.5","content-config-digest","70a3c4006d728440","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false},\"legacy\":{\"collections\":false}}","work",["Map",11,12,54,55,83,84,112,113,141,142,169,170],"nlp-customer-support",{"id":11,"data":13,"body":22,"filePath":23,"digest":24,"rendered":25},{"title":14,"description":15,"publishDate":16,"tags":17,"img":20,"img_alt":21},"NLP for Customer Support","BERT sentiment + BERTopic topic modeling on telecom call transcripts to surface complaint themes and coaching opportunities.\n",["Date","2025-07-10T00:00:00.000Z"],[18,19],"NLP","Topic Modeling","/assets/stock-2.png","Conversation bubbles overlaid on charts","This project builds an **NLP pipeline** to automatically extract themes and sentiment from telecom customer support conversations. Instead of manually reviewing thousands of transcripts, the system delivers structured insights that help identify emerging issues, track customer sentiment, and improve agent training.\n\n\n\n## Pipeline\n- **Sentiment Analysis (BERT):** Classifies each utterance as positive or negative to capture customer emotion at the sentence level.  \n- **Topic Modeling (BERTopic + Sentence Embeddings):** Groups related conversations into meaningful clusters (e.g., billing issues, technical failures).  \n- **Visualization:** Tracks how sentiment and topics shift across speakers and over time to highlight friction points.  \n\n**Data:** Talkmap Telecom Conversation Corpus (Hugging Face)  \n**Stack:** Python, Transformers, BERTopic, Sentence-Transformers, Pandas, Matplotlib  \n\n\n\n## Why this project\nI wanted to tackle a **real-world business pain point**: customer feedback is abundant but often trapped in unstructured text. Telecom companies process thousands of calls daily, but only a fraction are ever analyzed. By automating this process, businesses can surface trends, spot dissatisfaction early, and make evidence-based improvements in service delivery.\n\n\n\n## Approach\n- Built a modular pipeline to experiment with different NLP methods quickly.  \n- Balanced trade-offs between model accuracy and runtime efficiency, especially when processing long transcripts.  \n- Focused on interpretability — outputs are not just metrics but **visual narratives** that non-technical teams (support managers, trainers) can understand.  \n\n\n\n## Architecture / Pipeline\n1. **Data Preprocessing:** Clean raw transcripts (timestamps, fillers, speaker tags).  \n2. **Embedding Generation:** Encode utterances using Sentence Transformers.  \n3. **Sentiment Classification:** Apply a fine-tuned DistilBERT model for polarity.  \n4. **Topic Modeling:** Use BERTopic to cluster embeddings into coherent themes.  \n5. **Visualization:** Produce dashboards showing trends by agent, time, and topic.  \n\n\n\n## Results & Impact\n- Identified recurring themes such as *billing disputes* and *network outages* across thousands of conversations.  \n- Detected correlations between negative sentiment and long resolution times.  \n- Created visual dashboards that help supervisors **prioritize coaching** on specific topics.  \n\n\n\n## What I’d do next\n- Scale the pipeline to process **real-time streams** of support calls.  \n- Incorporate **multi-label classification** (e.g., issue type + urgency).  \n- Deploy dashboards via **Streamlit or Tableau** for easier adoption.  \n- Explore **LLM-based summarization** to complement topic modeling with concise call summaries.","src/content/work/nlp-customer-support.md","a07c7a54a1a93e77",{"html":26,"metadata":27},"\u003Cp>This project builds an \u003Cstrong>NLP pipeline\u003C/strong> to automatically extract themes and sentiment from telecom customer support conversations. Instead of manually reviewing thousands of transcripts, the system delivers structured insights that help identify emerging issues, track customer sentiment, and improve agent training.\u003C/p>\n\u003Ch2 id=\"pipeline\">Pipeline\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Sentiment Analysis (BERT):\u003C/strong> Classifies each utterance as positive or negative to capture customer emotion at the sentence level.\u003C/li>\n\u003Cli>\u003Cstrong>Topic Modeling (BERTopic + Sentence Embeddings):\u003C/strong> Groups related conversations into meaningful clusters (e.g., billing issues, technical failures).\u003C/li>\n\u003Cli>\u003Cstrong>Visualization:\u003C/strong> Tracks how sentiment and topics shift across speakers and over time to highlight friction points.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Data:\u003C/strong> Talkmap Telecom Conversation Corpus (Hugging Face)\u003Cbr>\n\u003Cstrong>Stack:\u003C/strong> Python, Transformers, BERTopic, Sentence-Transformers, Pandas, Matplotlib\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to tackle a \u003Cstrong>real-world business pain point\u003C/strong>: customer feedback is abundant but often trapped in unstructured text. Telecom companies process thousands of calls daily, but only a fraction are ever analyzed. By automating this process, businesses can surface trends, spot dissatisfaction early, and make evidence-based improvements in service delivery.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cul>\n\u003Cli>Built a modular pipeline to experiment with different NLP methods quickly.\u003C/li>\n\u003Cli>Balanced trade-offs between model accuracy and runtime efficiency, especially when processing long transcripts.\u003C/li>\n\u003Cli>Focused on interpretability — outputs are not just metrics but \u003Cstrong>visual narratives\u003C/strong> that non-technical teams (support managers, trainers) can understand.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cstrong>Data Preprocessing:\u003C/strong> Clean raw transcripts (timestamps, fillers, speaker tags).\u003C/li>\n\u003Cli>\u003Cstrong>Embedding Generation:\u003C/strong> Encode utterances using Sentence Transformers.\u003C/li>\n\u003Cli>\u003Cstrong>Sentiment Classification:\u003C/strong> Apply a fine-tuned DistilBERT model for polarity.\u003C/li>\n\u003Cli>\u003Cstrong>Topic Modeling:\u003C/strong> Use BERTopic to cluster embeddings into coherent themes.\u003C/li>\n\u003Cli>\u003Cstrong>Visualization:\u003C/strong> Produce dashboards showing trends by agent, time, and topic.\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cul>\n\u003Cli>Identified recurring themes such as \u003Cem>billing disputes\u003C/em> and \u003Cem>network outages\u003C/em> across thousands of conversations.\u003C/li>\n\u003Cli>Detected correlations between negative sentiment and long resolution times.\u003C/li>\n\u003Cli>Created visual dashboards that help supervisors \u003Cstrong>prioritize coaching\u003C/strong> on specific topics.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cul>\n\u003Cli>Scale the pipeline to process \u003Cstrong>real-time streams\u003C/strong> of support calls.\u003C/li>\n\u003Cli>Incorporate \u003Cstrong>multi-label classification\u003C/strong> (e.g., issue type + urgency).\u003C/li>\n\u003Cli>Deploy dashboards via \u003Cstrong>Streamlit or Tableau\u003C/strong> for easier adoption.\u003C/li>\n\u003Cli>Explore \u003Cstrong>LLM-based summarization\u003C/strong> to complement topic modeling with concise call summaries.\u003C/li>\n\u003C/ul>",{"headings":28,"localImagePaths":48,"remoteImagePaths":49,"frontmatter":50,"imagePaths":53},[29,33,36,39,42,45],{"depth":30,"slug":31,"text":32},2,"pipeline","Pipeline",{"depth":30,"slug":34,"text":35},"why-this-project","Why this project",{"depth":30,"slug":37,"text":38},"approach","Approach",{"depth":30,"slug":40,"text":41},"architecture--pipeline","Architecture / Pipeline",{"depth":30,"slug":43,"text":44},"results--impact","Results & Impact",{"depth":30,"slug":46,"text":47},"what-id-do-next","What I’d do next",[],[],{"title":14,"publishDate":51,"img":20,"img_alt":21,"description":15,"tags":52},["Date","2025-07-10T00:00:00.000Z"],[18,19],[],"qa-transformers",{"id":54,"data":56,"body":65,"filePath":66,"digest":67,"rendered":68},{"title":57,"description":58,"publishDate":59,"tags":60,"img":63,"img_alt":64},"Question Answering with Transformers","Interactive QA system on custom context using deepset/roberta-base-squad2; deployed on AWS with CUDA optimization.\n",["Date","2025-06-15T00:00:00.000Z"],[18,61,62],"LLM","Backend","/assets/stock-1.png","Code editor with transformer model diagram overlay","This project implements an end‑to‑end question answering pipeline using Hugging Face Transformers.\n\n**Highlights**\n- Cut inference latency by ~40% via mixed precision and CUDA memory profiling.\n- Profiled with `torch.profiler` and `nvidia-smi` to balance DL framework overheads and GPU utilization.\n- Accepts arbitrary context and returns extractive answers in real time.\n\n**Stack**: Python, PyTorch, Transformers, CUDA, AWS EC2/S3\n**Repo**: https://github.com/rheanair7/Question-Answering-with-Hugging-Face-Transformers.git\n\n## Why this project\nI wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\n\n## Approach\nBrief outline of the method, tradeoffs, and design choices.\n\n## Architecture / Pipeline\nA concise walkthrough of the components, data flow, and key libraries.\n\n## Results & Impact\nWhat worked, what improved, and evidence (metrics, examples, UX).\n\n## What I'd do next\nClear next steps to make this more robust or production-ready.","src/content/work/qa-transformers.md","9a8dde80b0de85ad",{"html":69,"metadata":70},"\u003Cp>This project implements an end‑to‑end question answering pipeline using Hugging Face Transformers.\u003C/p>\n\u003Cp>\u003Cstrong>Highlights\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Cut inference latency by ~40% via mixed precision and CUDA memory profiling.\u003C/li>\n\u003Cli>Profiled with \u003Ccode>torch.profiler\u003C/code> and \u003Ccode>nvidia-smi\u003C/code> to balance DL framework overheads and GPU utilization.\u003C/li>\n\u003Cli>Accepts arbitrary context and returns extractive answers in real time.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Stack\u003C/strong>: Python, PyTorch, Transformers, CUDA, AWS EC2/S3\n\u003Cstrong>Repo\u003C/strong>: \u003Ca href=\"https://github.com/rheanair7/Question-Answering-with-Hugging-Face-Transformers.git\">https://github.com/rheanair7/Question-Answering-with-Hugging-Face-Transformers.git\u003C/a>\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cp>Brief outline of the method, tradeoffs, and design choices.\u003C/p>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Cp>A concise walkthrough of the components, data flow, and key libraries.\u003C/p>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cp>What worked, what improved, and evidence (metrics, examples, UX).\u003C/p>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cp>Clear next steps to make this more robust or production-ready.\u003C/p>",{"headings":71,"localImagePaths":77,"remoteImagePaths":78,"frontmatter":79,"imagePaths":82},[72,73,74,75,76],{"depth":30,"slug":34,"text":35},{"depth":30,"slug":37,"text":38},{"depth":30,"slug":40,"text":41},{"depth":30,"slug":43,"text":44},{"depth":30,"slug":46,"text":47},[],[],{"title":57,"publishDate":80,"img":63,"img_alt":64,"description":58,"tags":81},["Date","2025-06-15T00:00:00.000Z"],[18,61,62],[],"precious-metals-dashboard",{"id":83,"data":85,"body":94,"filePath":95,"digest":96,"rendered":97},{"title":86,"description":87,"publishDate":88,"tags":89,"img":92,"img_alt":93},"Precious Metal Prices Dashboard","Dash + Plotly app to explore daily prices for Gold, Silver, Platinum, Palladium (2018–2021) with filters and date picker.\n",["Date","2022-07-15T00:00:00.000Z"],[90,91],"Dashboards","Visualization","/assets/stock-6.png","Time series line charts in a dark UI","Interactive dashboard for exploring precious metal price trends.\n\n**Features**\n- Line charts with metal filters and date range picker.\n- Dark theme for readability; responsive layout.\n- Callback‑driven updates for smooth interactions.\n\n**Stack**: Dash, Plotly, Pandas\n\n## Why this project\nI wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\n\n## Approach\nBrief outline of the method, tradeoffs, and design choices.\n\n## Architecture / Pipeline\nA concise walkthrough of the components, data flow, and key libraries.\n\n## Results & Impact\nWhat worked, what improved, and evidence (metrics, examples, UX).\n\n## What I'd do next\nClear next steps to make this more robust or production-ready.","src/content/work/precious-metals-dashboard.md","c1d56a708021a898",{"html":98,"metadata":99},"\u003Cp>Interactive dashboard for exploring precious metal price trends.\u003C/p>\n\u003Cp>\u003Cstrong>Features\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Line charts with metal filters and date range picker.\u003C/li>\n\u003Cli>Dark theme for readability; responsive layout.\u003C/li>\n\u003Cli>Callback‑driven updates for smooth interactions.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Stack\u003C/strong>: Dash, Plotly, Pandas\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cp>Brief outline of the method, tradeoffs, and design choices.\u003C/p>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Cp>A concise walkthrough of the components, data flow, and key libraries.\u003C/p>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cp>What worked, what improved, and evidence (metrics, examples, UX).\u003C/p>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cp>Clear next steps to make this more robust or production-ready.\u003C/p>",{"headings":100,"localImagePaths":106,"remoteImagePaths":107,"frontmatter":108,"imagePaths":111},[101,102,103,104,105],{"depth":30,"slug":34,"text":35},{"depth":30,"slug":37,"text":38},{"depth":30,"slug":40,"text":41},{"depth":30,"slug":43,"text":44},{"depth":30,"slug":46,"text":47},[],[],{"title":86,"publishDate":109,"img":92,"img_alt":93,"description":87,"tags":110},["Date","2022-07-15T00:00:00.000Z"],[90,91],[],"tifr-marl-neuroevolution",{"id":112,"data":114,"body":123,"filePath":124,"digest":125,"rendered":126},{"title":115,"description":116,"publishDate":117,"tags":118,"img":121,"img_alt":122},"Multi‑Agent RL with Neuro Evolution (TIFR)","Neuro Evolution‑based multi‑agent RL in PyTorch; 85% training efficiency improvement with distributed preprocessing.\n",["Date","2023-11-01T00:00:00.000Z"],[119,120],"Reinforcement Learning","Research","/assets/stock-5.png","RL agents in a simulated environment diagram","Designed and executed multi‑agent reinforcement learning simulations.\n\n**Impact**\n- ~85% training efficiency improvement over baseline variants.\n- Large‑scale experiment data across NoSQL (JSON) and SQL.\n\n**Infra**\n- Distributed preprocessing/analysis with **Hadoop + Spark**.\n\n**Stack**: Python, PyTorch, NumPy, Hadoop, Spark\n\n## Why this project\nI wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\n\n## Approach\nBrief outline of the method, tradeoffs, and design choices.\n\n## Architecture / Pipeline\nA concise walkthrough of the components, data flow, and key libraries.\n\n## Results & Impact\nWhat worked, what improved, and evidence (metrics, examples, UX).\n\n## What I'd do next\nClear next steps to make this more robust or production-ready.","src/content/work/tifr-marl-neuroevolution.md","debba3370a17472e",{"html":127,"metadata":128},"\u003Cp>Designed and executed multi‑agent reinforcement learning simulations.\u003C/p>\n\u003Cp>\u003Cstrong>Impact\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>~85% training efficiency improvement over baseline variants.\u003C/li>\n\u003Cli>Large‑scale experiment data across NoSQL (JSON) and SQL.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Infra\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Distributed preprocessing/analysis with \u003Cstrong>Hadoop + Spark\u003C/strong>.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Stack\u003C/strong>: Python, PyTorch, NumPy, Hadoop, Spark\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cp>Brief outline of the method, tradeoffs, and design choices.\u003C/p>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Cp>A concise walkthrough of the components, data flow, and key libraries.\u003C/p>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cp>What worked, what improved, and evidence (metrics, examples, UX).\u003C/p>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cp>Clear next steps to make this more robust or production-ready.\u003C/p>",{"headings":129,"localImagePaths":135,"remoteImagePaths":136,"frontmatter":137,"imagePaths":140},[130,131,132,133,134],{"depth":30,"slug":34,"text":35},{"depth":30,"slug":37,"text":38},{"depth":30,"slug":40,"text":41},{"depth":30,"slug":43,"text":44},{"depth":30,"slug":46,"text":47},[],[],{"title":115,"publishDate":138,"img":121,"img_alt":122,"description":116,"tags":139},["Date","2023-11-01T00:00:00.000Z"],[119,120],[],"vt-research-automation",{"id":141,"data":143,"body":151,"filePath":152,"digest":153,"rendered":154},{"title":144,"description":145,"publishDate":146,"tags":147,"img":149,"img_alt":150},"Research Workflow Automation (Virginia Tech)","Automated academic paper parsing & classification; reduced review cycle from ~14 days to ~2 days with Python workflows.\n",["Date","2024-06-15T00:00:00.000Z"],[148,18],"Automation","/assets/stock-4.png","Documents and charts illustrating automated workflows","Automation that accelerated faculty research.\n\n**What I built**\n- Parsers + metadata extraction with **BeautifulSoup**, **Pandas**.\n- NLP classifiers (spaCy + scikit‑learn) → faster categorization.\n- Summary reports & visuals (Matplotlib, Seaborn).\n\n**Outcome**: ~85% efficiency gain; ~70% reduction in manual review time.\n\n## Why this project\nI wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\n\n## Approach\nBrief outline of the method, tradeoffs, and design choices.\n\n## Architecture / Pipeline\nA concise walkthrough of the components, data flow, and key libraries.\n\n## Results & Impact\nWhat worked, what improved, and evidence (metrics, examples, UX).\n\n## What I'd do next\nClear next steps to make this more robust or production-ready.","src/content/work/vt-research-automation.md","f610d5228533dcb7",{"html":155,"metadata":156},"\u003Cp>Automation that accelerated faculty research.\u003C/p>\n\u003Cp>\u003Cstrong>What I built\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Parsers + metadata extraction with \u003Cstrong>BeautifulSoup\u003C/strong>, \u003Cstrong>Pandas\u003C/strong>.\u003C/li>\n\u003Cli>NLP classifiers (spaCy + scikit‑learn) → faster categorization.\u003C/li>\n\u003Cli>Summary reports &#x26; visuals (Matplotlib, Seaborn).\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Outcome\u003C/strong>: ~85% efficiency gain; ~70% reduction in manual review time.\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cp>Brief outline of the method, tradeoffs, and design choices.\u003C/p>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Cp>A concise walkthrough of the components, data flow, and key libraries.\u003C/p>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cp>What worked, what improved, and evidence (metrics, examples, UX).\u003C/p>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cp>Clear next steps to make this more robust or production-ready.\u003C/p>",{"headings":157,"localImagePaths":163,"remoteImagePaths":164,"frontmatter":165,"imagePaths":168},[158,159,160,161,162],{"depth":30,"slug":34,"text":35},{"depth":30,"slug":37,"text":38},{"depth":30,"slug":40,"text":41},{"depth":30,"slug":43,"text":44},{"depth":30,"slug":46,"text":47},[],[],{"title":144,"publishDate":166,"img":149,"img_alt":150,"description":145,"tags":167},["Date","2024-06-15T00:00:00.000Z"],[148,18],[],"online-retail-intelligence",{"id":169,"data":171,"body":180,"filePath":181,"digest":182,"rendered":183},{"title":172,"description":173,"publishDate":174,"tags":175,"img":178,"img_alt":179},"Online Retail Customer Intelligence Study","Segmentation, association rules, and Holt–Winters forecasting on the UCI Online Retail II dataset with Tableau dashboards.\n",["Date","2025-03-01T00:00:00.000Z"],[176,177,90],"Analytics","Forecasting","/assets/stock-3.png","Dashboard preview showing retail KPIs and charts","Built a comprehensive customer intelligence pipeline for a UK giftware retailer.\n\n**What I did**\n- **RFM Segmentation** → targeted campaigns & retention.\n- **Apriori** → bundles/cross‑sell opportunities.\n- **Holt–Winters** → demand forecasting across products and geographies.\n- Interactive **Tableau dashboards** for stakeholders.\n\n**Stack**: Python, Pandas, Apriori, Holt–Winters, Tableau  \n**Repo**: https://github.com/rheanair7/Online-retail-customer-intelligence-study.git\n\n## Why this project\nI wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\n\n## Approach\nBrief outline of the method, tradeoffs, and design choices.\n\n## Architecture / Pipeline\nA concise walkthrough of the components, data flow, and key libraries.\n\n## Results & Impact\nWhat worked, what improved, and evidence (metrics, examples, UX).\n\n## What I'd do next\nClear next steps to make this more robust or production-ready.","src/content/work/online-retail-intelligence.md","0d0e18be5d559e58",{"html":184,"metadata":185},"\u003Cp>Built a comprehensive customer intelligence pipeline for a UK giftware retailer.\u003C/p>\n\u003Cp>\u003Cstrong>What I did\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>RFM Segmentation\u003C/strong> → targeted campaigns &#x26; retention.\u003C/li>\n\u003Cli>\u003Cstrong>Apriori\u003C/strong> → bundles/cross‑sell opportunities.\u003C/li>\n\u003Cli>\u003Cstrong>Holt–Winters\u003C/strong> → demand forecasting across products and geographies.\u003C/li>\n\u003Cli>Interactive \u003Cstrong>Tableau dashboards\u003C/strong> for stakeholders.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Stack\u003C/strong>: Python, Pandas, Apriori, Holt–Winters, Tableau\u003Cbr>\n\u003Cstrong>Repo\u003C/strong>: \u003Ca href=\"https://github.com/rheanair7/Online-retail-customer-intelligence-study.git\">https://github.com/rheanair7/Online-retail-customer-intelligence-study.git\u003C/a>\u003C/p>\n\u003Ch2 id=\"why-this-project\">Why this project\u003C/h2>\n\u003Cp>I wanted to solve a concrete problem and learn by building. This section explains the motivation and the end user value.\u003C/p>\n\u003Ch2 id=\"approach\">Approach\u003C/h2>\n\u003Cp>Brief outline of the method, tradeoffs, and design choices.\u003C/p>\n\u003Ch2 id=\"architecture--pipeline\">Architecture / Pipeline\u003C/h2>\n\u003Cp>A concise walkthrough of the components, data flow, and key libraries.\u003C/p>\n\u003Ch2 id=\"results--impact\">Results &#x26; Impact\u003C/h2>\n\u003Cp>What worked, what improved, and evidence (metrics, examples, UX).\u003C/p>\n\u003Ch2 id=\"what-id-do-next\">What I’d do next\u003C/h2>\n\u003Cp>Clear next steps to make this more robust or production-ready.\u003C/p>",{"headings":186,"localImagePaths":192,"remoteImagePaths":193,"frontmatter":194,"imagePaths":197},[187,188,189,190,191],{"depth":30,"slug":34,"text":35},{"depth":30,"slug":37,"text":38},{"depth":30,"slug":40,"text":41},{"depth":30,"slug":43,"text":44},{"depth":30,"slug":46,"text":47},[],[],{"title":172,"publishDate":195,"img":178,"img_alt":179,"description":173,"tags":196},["Date","2025-03-01T00:00:00.000Z"],[176,177,90],[],"education",["Map",200,201,211,212,220,221,228,229],"01-cu-boulder",{"id":200,"data":202,"filePath":209,"digest":210},{"school":203,"degree":204,"start":205,"end":206,"details":207,"order":208},"University of Colorado Boulder","M.S. Computer Science","2025","2027","Coursework: Machine Learning, Cybersecurity, Data Systems",1,"src/content/education/01-cu-boulder.json","e6e6967816aa6bff","02-vt-msba",{"id":211,"data":213,"filePath":218,"digest":219},{"school":214,"degree":215,"start":216,"end":205,"details":217,"order":30},"Virginia Tech","M.S. Business Analytics","2024","CGPA: 3.97/4.00","src/content/education/02-vt-msba.json","414f5dbdea2304c3","03-bs-vt",{"id":220,"data":222,"filePath":226,"digest":227},{"school":214,"degree":223,"start":224,"end":216,"details":217,"order":225},"BS in Cybersecurity Management and Analytics","2023",3,"src/content/education/03-bs-vt.json","322c6df2cd666dae","04-btech-nmims",{"id":228,"data":230,"filePath":236,"digest":237},{"school":231,"degree":232,"start":233,"end":224,"details":234,"order":235},"Narsee Monjee Institute of Management and Technology (NMIMS)","B.Tech in Computer Science","2020","CGPA: 3.70/4.00",4,"src/content/education/04-btech-nmims.json","0068c58baa573e20"]